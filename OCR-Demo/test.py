from transformers import DonutProcessor, VisionEncoderDecoderModel
from datasets import load_dataset
import torch
from PIL import Image
import random

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ëª¨ë¸ ë° í”„ë¡œì„¸ì„œ ë¡œë“œ
processor = DonutProcessor.from_pretrained("naver-clova-ix/donut-base-finetuned-cord-v2")
model = VisionEncoderDecoderModel.from_pretrained("naver-clova-ix/donut-base-finetuned-cord-v2").to(device)

# ë°ì´í„°ì…‹ ë¡œë“œ
# dataset = load_dataset("naver-clova-ix/cord-v2", split="train")
dataset = load_dataset("naver-clova-ix/synthdog-ko", split="train")

# ëœë¤ ì¸ë±ìŠ¤ ì„ íƒ
random_idx = random.randint(0, len(dataset) - 1)

image = dataset[random_idx]["image"]
ground_truth = dataset[random_idx]["ground_truth"]
# image = Image.open("F:/image/receipt/online/2.png")
# image = Image.open("F:/image/receipt/r (3).jpg")

# ëª¨ë¸ ì…ë ¥ ì „ì²˜ë¦¬
pixel_values = processor(image, return_tensors="pt").pixel_values.to(device)

# ë””ì½”ë”©ìš© prompt (Donutì€ JSON í˜•íƒœë¡œ ì¶”ì¶œ)
task_prompt = "<s_cord-v2>"  # ëª¨ë¸ì´ ì‚¬ìš©í•˜ëŠ” í”„ë¡¬í”„íŠ¸ í† í°
decoder_input_ids = processor.tokenizer(task_prompt, add_special_tokens=False, return_tensors="pt").input_ids
decoder_input_ids = decoder_input_ids.to(device)

# ì¶”ë¡ 
outputs = model.generate(pixel_values, decoder_input_ids=decoder_input_ids, max_length=768)
result = processor.batch_decode(outputs, skip_special_tokens=True)[0]

print("ğŸ“„ ì •ë‹µ:")
print(ground_truth)

print("ğŸ“„ Donut OCR ì¸ì‹ ê²°ê³¼:")
print(result)
image.show()
